\section{CPUs versus GPUs}
Heterogeneous systems containing CPUs and accelerators allow us to reach higher computational speeds while keeping power consumption at acceptable levels. The most common accelerators nowadays, GPUs, are very different compared to state-of-the-art general-purpose CPUs. While CPUs incorporate large caches and complex logic for out-of-order execution, branch prediction, and speculation, GPUs contain significantly more floating point units. They have in-order cores which hide pipeline stalls through interleaved multithreading, e.g. allowing up to 1536 concurrent threads per core\footnote{In Nvidia terminology a core is called Streaming Multi-Processor.}.
Garland et al.~\cite{garland2010} refer to CPUs as latency oriented processors with complex techniques used for extracting Instruction Level Parallelism (ILP) from sequential programs. In contrast, GPUs are throughput oriented, containing a large number of cores (e.g. 16) with wide SIMD units (e.g. 32 lanes), making them ideal architectures for vectorizable codes. All applications can be run on CPUs but only a subset can be ported to or deliver good performance on GPUs, making them special purpose processors. In the following, we refer to GPUs and CPUs as processors, but of different type.

% Given their specific architectural characteristics, programming the CPU and the GPU is inherently different. 
Programming the CPU and the GPU is inherently different. 
Multi-core CPUs are programmed using threads through pthreads or OpenMP.
For GPU programming, CUDA is also based on threads,
but there are differences. For synchronization,
CUDA only provides barriers within thread groups running on the same GPU core, and atomic operations. For performance, the architectural details of GPUs have to be considered.
Maximizing the number of threads running concurrently on the GPU, coalescing accesses to global memory, eliminating bank conflicts, minimizing the number of branches, and utilizing the various memories appropriately (global, shared, texture, constant) are important GPU optimizations.
% In contrast, CPU optimizations include blocking at different memory levels and arranging and aligning data for SSE / AVX operations.
In contrast, CPU optimizations include cache blocking and vectorization.